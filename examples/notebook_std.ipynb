{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "from src.models.model import NBeatsNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utils.\n",
    "def plot_scatter(*args, **kwargs):\n",
    "    plt.plot(*args, **kwargs)\n",
    "    plt.scatter(*args, **kwargs)\n",
    "\n",
    "\n",
    "# simple batcher.\n",
    "def data_generator(x, y, size):\n",
    "    assert len(x) == len(y)\n",
    "    batches = []\n",
    "    for ii in range(0, len(x), size):\n",
    "        batches.append((x[ii:ii + size], y[ii:ii + size]))\n",
    "    for batch in batches:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/utkarshpratiush/Cr_D/modeling/data/master_dataset_merged_2023021518.parquet\")\n",
    "df = df[['date', 'target_w']]\n",
    "series_std = df.groupby('date').apply(pd.DataFrame.std, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-17</th>\n",
       "      <td>0.040185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-24</th>\n",
       "      <td>0.047002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-02</th>\n",
       "      <td>0.036563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-09</th>\n",
       "      <td>0.031037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>0.031536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>0.030201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14</th>\n",
       "      <td>0.032864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>0.021859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0.025964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.024660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_w\n",
       "date                \n",
       "2016-02-17  0.040185\n",
       "2016-02-24  0.047002\n",
       "2016-03-02  0.036563\n",
       "2016-03-09  0.031037\n",
       "2016-03-16  0.031536\n",
       "...              ...\n",
       "2022-12-07  0.030201\n",
       "2022-12-14  0.032864\n",
       "2022-12-21  0.021859\n",
       "2022-12-28  0.025964\n",
       "2023-01-04  0.024660\n",
       "\n",
       "[360 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_length = 1\n",
    "backcast_length = 52 * forecast_length\n",
    "batch_size = 128  # greater than 4 for viz\n",
    "\n",
    "#print(series.head())\n",
    "series = series_std.values.flatten()  # just keep np array here for simplicity.\n",
    "\n",
    "# data backcast/forecast generation.\n",
    "x, y = [], []\n",
    "for epoch in range(backcast_length, len(series) - forecast_length):\n",
    "    x.append(series[epoch - backcast_length:epoch])\n",
    "    y.append(series[epoch:epoch + forecast_length])\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# split train/test.\n",
    "c = int(len(x) * 0.8)\n",
    "x_train, y_train = x[:c], y[:c]\n",
    "x_test, y_test = x[c:], y[c:]\n",
    "\n",
    "# normalization.\n",
    "norm_constant = np.max(x_train)\n",
    "x_train, y_train = x_train / norm_constant, y_train / norm_constant\n",
    "x_test, y_test = x_test / norm_constant, y_test / norm_constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307, 52), (307, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=52, forecast_length=1, share_thetas=False) at @4947302672\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=52, forecast_length=1, share_thetas=False) at @4865719264\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=52, forecast_length=1, share_thetas=False) at @4940352384\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=52, forecast_length=1, share_thetas=False) at @4947302576\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=52, forecast_length=1, share_thetas=False) at @4947301376\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=52, forecast_length=1, share_thetas=False) at @4947302720\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "net = NBeatsNet(\n",
    "    stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK),\n",
    "    forecast_length=forecast_length,\n",
    "    backcast_length=backcast_length,\n",
    "    hidden_layer_units=128,\n",
    ")\n",
    "optimiser = optim.Adam(lr=1e-4, params=net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:00<00:12, 81.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0000, grad_step = 000002, tr_loss (epoch) = 209.695, te_loss (epoch) = 178.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 111/1000 [00:01<00:08, 101.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0100, grad_step = 000202, tr_loss (epoch) = 7.299, te_loss (epoch) = 3.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 219/1000 [00:02<00:07, 104.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0200, grad_step = 000402, tr_loss (epoch) = 3.563, te_loss (epoch) = 2.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 318/1000 [00:03<00:06, 105.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0300, grad_step = 000602, tr_loss (epoch) = 1.380, te_loss (epoch) = 2.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 417/1000 [00:04<00:05, 105.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0400, grad_step = 000802, tr_loss (epoch) = 0.388, te_loss (epoch) = 2.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 516/1000 [00:05<00:04, 105.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0500, grad_step = 001002, tr_loss (epoch) = 0.247, te_loss (epoch) = 2.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 615/1000 [00:06<00:03, 100.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0600, grad_step = 001202, tr_loss (epoch) = 0.140, te_loss (epoch) = 2.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 714/1000 [00:06<00:02, 101.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0700, grad_step = 001402, tr_loss (epoch) = 0.095, te_loss (epoch) = 2.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 813/1000 [00:07<00:01, 99.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0800, grad_step = 001602, tr_loss (epoch) = 0.062, te_loss (epoch) = 2.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 912/1000 [00:08<00:00, 105.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0900, grad_step = 001802, tr_loss (epoch) = 0.038, te_loss (epoch) = 2.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 102.14it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grad_step = 0\n",
    "for epoch in tqdm(range(1000)):\n",
    "    # train.\n",
    "    net.train()\n",
    "    train_loss = []\n",
    "    for x_train_batch, y_train_batch in data_generator(x_train, y_train, batch_size):\n",
    "        grad_step += 1\n",
    "        optimiser.zero_grad()\n",
    "        _, forecast = net(torch.tensor(x_train_batch, dtype=torch.float).to(net.device))\n",
    "        loss = F.mse_loss(forecast, torch.tensor(y_train_batch, dtype=torch.float).to(net.device))\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    # test.\n",
    "    net.eval()\n",
    "    _, forecast = net(torch.tensor(x_test, dtype=torch.float))\n",
    "    test_loss = F.mse_loss(forecast, torch.tensor(y_test, dtype=torch.float)).item()\n",
    "    p = forecast.detach().numpy()\n",
    "    if epoch % 100 == 0:\n",
    "        #with torch.no_grad():\n",
    "        #    save(net, optimiser, grad_step)\n",
    "        print(f'epoch = {str(epoch).zfill(4)}, '\n",
    "                f'grad_step = {str(grad_step).zfill(6)}, '\n",
    "                f'tr_loss (epoch) = {1000 * train_loss:.3f}, '\n",
    "                f'te_loss (epoch) = {1000 * test_loss:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c_dao_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
